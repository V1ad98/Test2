import pandas as pd
import numpy as np
import math
import warnings

#↓↓↓2function↓↓↓###################################################################################################################################################################
##### This is the actual binning function for numeric variables and factors. #####
def woe_binning_2 (df, target_var, pred_var, min_perc_total, min_perc_class, stop_limit, abbrev_fact_levels, bad, good):
    
    #### Build subsets with target and predictor variable
    df = pd.DataFrame([[target_var, pred_var]]) # used for final binning
    dfrm = pd.DataFrame([[target_var, pred_var]], columns=['target_var', 'predictor_var']) # used for iterative merging of bins


    #### Check if numerical variable or factor was provided as predictor and apply appropriate binning technique

    ### Binning in case a numerical variable was selected
    if len(dfrm.credit_risk.drop_duplicates()) == 2 and (dfrm.predictor_var.dtypes.kind in 'bifc') == True:
        

        ## Derive number of initial bins from min.perc.total parameter
        max_bins = math.trunc(1/min_perc_total)
        
        ## Derive cutpoints for bins (with similar frequency)
        cutpoints = dfrm.predictor_var.quantile(np.arange(0,max_bins+1)/max_bins)
        #innercutpoints = cutpoints[np.arange(0.5,len(cutpoints)-2,0.5)]   # remove outer (observed) boudaries
        innercutpoints = cutpoints.median()
        cutpoints = [-np.inf, innercutpoints, +np.inf]   # add -Inf, +Inf to cutpoints
        #cutpoints = cutpoints.drop_duplicates()   # remove multiple cutpoints with same value
        
        ## Calculate initial crosstab from binned variable and target variable
        ## to identify and merge sparse bins
        
        # Compute binned variable from cutpoints and add it to the subset data frame
        dfrm["predictor_var_binned"] = pd.cut(dfrm["predictor_var"], cutpoints, right=True, labels = None,
            retbins=False, precision=10, include_lowest=False)
            
        ##dfrm$predictor.var.binned <- cut(dfrm$predictor.var, cutpoints, labels = NULL,include.lowest = FALSE, right = TRUE, dig.lab = 10,ordered_result = TRUE)
    
    
        # Compute crosstab from binned variable and target variable and covert it to a data frame
        freq_table = pd.crosstab(dfrm["predictor_var_binned"],dfrm["predictor_var"], dropna=True)
        freq_table.fillna('Missing')
        woe_dfrm = pd.DataFrame(freq_table) # Convert frequency table to data frame
#Test↓↓↓###################################################################################################################################################################        
        woe_dfrm = woe_dfrm[['good', 'bad']]  # Select columns with raw frequencies only
        # Compute columns percents for target classes from crosstab frequencies
        woe_dfrm["col_perc_a"] = woe_dfrm.good/sum(woe_dfrm.good)
        woe_dfrm["col_perc_b"] = woe_dfrm.bad/sum(woe_dfrm.bad)
        # Correct column percents in case of 0 frequencies (in case of no NA skip last row)
        if pd.isna(df.pred_var)==False:
#↓↓↓???↓↓↓???????####################################################################################################################################################################            
            #???if ( min(woe.dfrm[-nrow(woe.dfrm),1],na.rm=TRUE)==0 | min(woe.dfrm[-nrow(woe.dfrm),2],na.rm=TRUE)==0 )
            if woe_dfrm.min(len(woe_dfrm.index),0)==0 or woe_dfrm.min(len(woe_dfrm.index),2)==0:
    			woe.dfrm$col.perc.a[-nrow(woe.dfrm)] <- (woe.dfrm$col.perc.a[-nrow(woe.dfrm)]+0.0001)/sum(woe.dfrm$col.perc.a[-nrow(woe.dfrm)]+0.0001)
    			woe.dfrm$col.perc.b[-nrow(woe.dfrm)] <- (woe.dfrm$col.perc.b[-nrow(woe.dfrm)]+0.0001)/sum(woe.dfrm$col.perc.b[-nrow(woe.dfrm)]+0.0001)	

    	else
    		if ( min(woe.dfrm[,1],na.rm=TRUE)==0 | min(woe.dfrm[,2],na.rm=TRUE)==0 ) {
    			woe.dfrm$col.perc.a <- (woe.dfrm$col.perc.a+0.0001)/sum(woe.dfrm$col.perc.a+0.0001)
    			woe.dfrm$col.perc.b <- (woe.dfrm$col.perc.b+0.0001)/sum(woe.dfrm$col.perc.b+0.0001)	

        # Check for bins (without last regular and without NA bin) if frequencies < percentage limit specified above
	# (in reverse order to remain correct reference to cutpoints)
	for i in range(len(woe_dfrm.index)-2,1):
		if (woe_dfrm["col_perc_a"][i]<min_perc_class or woe_dfrm[col_perc_b][i]<min_perc_class or ???((woe.dfrm[i,1]+woe.dfrm[i,2])/(sum(woe.dfrm[,1],na.rm=TRUE)+sum(woe.dfrm[,2],na.rm=TRUE)))<min.perc.total) {
			# Remove cutpoint			
			cutpoints <- cutpoints[-c((i+1))]
                    
                    
                    
#↓↓↓1function↓↓↓###################################################################################################################################################################    
def woe_binning (df, target_var, pred_var, min_perc_total, min_perc_class, stop_limit, abbrev_fact_levels, event_class):
    
#### Warning message and defaults in case parameters are not specified
    if df.isna()==True or df.target_var.isna() ==True or df.pred_var.isna() ==True:
        warnings.warn("Incorrect specification of data frame and/or variables.")
    
    if pd.isnull(min_perc_total)==True:
        min_perc_total=0.05
        
    if min_perc_total<0.0001 or min_perc_total>0.2 or (min_perc_total.dtypes.kind in 'bifc') ==False:
        warnings.warn("Incorrect parameter specification; accepted min.perc.total parameter range is 0.0001-0.2. Parameter was set to default (0.05).")
        min_perc_total=0.05
        
    if pd.isnull(min_perc_class)==True:
        min_perc_class=0
        
    if min_perc_class<0 or min_perc_class>0.2 or (min_perc_class.dtypes.kind in 'bifc') ==False:
        warnings.warn("Incorrect parameter specification; accepted min.perc.class parameter range is 0-0.2. Parameter was set to default (0).")
        min_perc_class=0
        
    if pd.isnull(stop_limit)==True:
        stop_limit=0.1
        
    if stop_limit<0 or stop_limit>0.5 or (stop_limit.dtypes.kind in 'bifc') ==False:
        warnings.warn("Incorrect parameter specification; accepted stop.limit parameter range is 0-0.05. Parameter was set to default (0.1).")
        stop_limit=0.1
        
    if pd.isnull(abbrev_fact_levels)==True:
        abbrev_fact_levels=200
        
    if abbrev_fact_levels<0 or abbrev_fact_levels>1000:
        warnings.warn("Incorrect parameter specification; accepted abbrev.fact.levels parameter range is 0-10000. Parameter was set to default (200).")
        abbrev_fact_levels=200

    #### Display warning message in case of incorrect target variable specification
    if len(dfrm.credit_risk.isna().drop_duplicates())!=2:
        warnings.warn("Incorrect variable specification.\nTarget variable must have two distinct values (NAs are accepted).")

    #### Display warning message in case none of the target classes matches the specified event.class parameter
    if pd.isnull(event_class)==False:
        if df.target_var.drop_duplicates()[0]==event_class or df.target_var.drop_duplicates()[1]==event_class==False:
            warnings.warn("None of the target classes matches the specified event.class parameter.")
    
    #### In case bad class was specified assign 'good' and 'bad' codes (the latter will be associated with negative WOE values then)
    if pd.isnull(event_class)==False: 
        if df.target_var.drop_duplicates()[0]==event_class:
            bad = df.target_var.drop_duplicates()[0]
            good = df.target_var.drop_duplicates()[1]
        else:
            bad = df.target_var.drop_duplicates()[1]
            good = df.target_var.drop_duplicates()[0]
            
    else:
        bad = df.target_var.drop_duplicates()[0]
        good = df.target_var.drop_duplicates()[1]
        
    bad = str(bad)
    good = str(good)
    
    #### Gather names and look-up tables (with binned classes and WOE values) for each predictor variable in a list
    if  isinstance(pred_var, pd.DataFrame)==True:
        pred_var = list(df.drop("target_var",1))  # convert variable names of data frame into a list (without target variable)
    else:
        list(pred_var)   # provide variable name(s) as a list

    #### Subset: consider only cases without NA in target variable
    df = df[df.target_var.isna()==False]       
    #### Call actual binning function and put binning solutions together with respective variable names into a list
    binning = pred_var.apply(lambda x: woe_binning_2(df, target_var, x, min_perc_total, min_perc_class, stop_limit, abbrev_fact_levels, bad, good))
#↓↓↓???↓↓↓???????#################################################################################################################################################################### 
    
    #### Read names and IV total values in the list and put them together with the binning tables
    names_of_pred_var = pred_var.apply(lambda x: x)
    iv_total_list = binning.apply(lambda x: colMeans(x[3]))
    binning = DataFrame.as_matrix(columns=["names_of_pred_var, binning, iv_total_list"])

    #### Sort via IV total
    binning = binning.sort((binning.iv_total_list.dtypes.kind in 'bifc') == True)
    
    
        
woe_binning (df, target_var, pred_var, min_perc_total, min_perc_class, stop_limit, abbrev_fact_levels, event_class)
